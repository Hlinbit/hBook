{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a model from onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(\"resnet50-v2-7.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib.download import download_testdata\n",
    "import numpy as np\n",
    "\n",
    "img_url = \"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\"\n",
    "img_path = download_testdata(img_url, \"imagenet_cat.png\", module=\"data\")\n",
    "\n",
    "# Resize it to 224x224\n",
    "resized_image = Image.open(img_path).resize((224, 224))\n",
    "img_data = np.asarray(resized_image).astype(\"float32\")\n",
    "\n",
    "# Our input image is in HWC layout while ONNX expects CHW input, so convert the array\n",
    "img_data = np.transpose(img_data, (2, 0, 1))\n",
    "\n",
    "# Normalize according to the ImageNet input specification\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev\n",
    "\n",
    "# Add the batch dimension, as we are expecting 4-dimensional input: NCHW.\n",
    "img_data = np.expand_dims(norm_img_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the ONNX to Relay model\n",
    "\n",
    "The `relay.frontend.from_onnx` function is called with the ONNX model and the shape dictionary as arguments. It converts the ONNX model to a Relay module (mod) and extracts the parameters (params) from the ONNX model. \n",
    "\n",
    "The mod object represents the computation graph and can be further optimized and executed using TVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import relay\n",
    "\n",
    "# Specify model running target\n",
    "target = \"llvm\"\n",
    "\n",
    "# Specify data format\n",
    "input_name = \"data\"\n",
    "shape_dict = {input_name: img_data.shape}\n",
    "\n",
    "# converts the ONNX model to a Relay module \n",
    "mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Relay module (mod) into an TVM module\n",
    "\n",
    "With the `tvm.transform.PassContext(opt_level=3)` block, we are creating a `PassContext` object to specify the optimization level for the subsequent operations. The `opt_level=3` indicates a high level of optimization.\n",
    "\n",
    "Then, we use the `relay.build` function to compile the Relay module (mod) into a TVM module that is an intermediate representation. \n",
    "\n",
    "By executing this code snippet, the Relay module will be optimized using the specified optimization level, compiled into a TVM module, and assigned to the lib variable for further usage or deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`tvm.device(str(target), 0)` creates a device object using the TVM library's tvm.device() function. The second argument \"0\" is the device index, which is used when there are multiple devices of the same type (e.g., multiple GPUs).\n",
    "\n",
    "`graph_executor.GraphModule(lib[\"default\"](dev))` creates a GraphModule object, which is a TVM construct used to execute compiled models. The lib object is likely a pre-compiled TVM module that contains the compiled model, and the \"default\" key is used to access the default module. The dev object, which represents the target device, is passed to the lib[\"default\"] function to ensure that the module is executed on the correct device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_executor\n",
    "\n",
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the module\n",
    "\n",
    "`module.get_output(0, tvm.nd.empty(output_shape))` creates an empty TVM NDArray object with shape `output_shape` to store the output result. The first para indicates the index of the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "module.set_input(input_name, img_data)\n",
    "module.run()\n",
    "output_shape = (1, 1000)\n",
    "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the model\n",
    "\n",
    "## create a TVM runner\n",
    "\n",
    "The runner takes compiled code that is generated with a specific set of parameters and measures the performance of it. \n",
    "- Parameter `number` specifies the number of times the model inference should be executed for each measurement.\n",
    "- Parameter `repeat` specifies the number of times the entire measurement process (with number runs) should be repeated.\n",
    "- Parameter `timeout` sets the timeout (in seconds) for each measurement run.\n",
    "- Parameter `min_repeat_ms` sets the minimum duration (in milliseconds) for each measurement run. If the number of repeats falls under this time, it will be increased. \n",
    "- Parameter `enable_cpu_cache_flush` is specific to CPU-based models. When set to True, it ensures that the CPU cache is flushed before each measurement run, which can help provide more consistent and accurate performance measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import autotvm\n",
    "\n",
    "number = 10\n",
    "repeat = 1\n",
    "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
    "timeout = 10  # in seconds\n",
    "\n",
    "runner = autotvm.LocalRunner(\n",
    "    number=number,\n",
    "    repeat=repeat,\n",
    "    timeout=timeout,\n",
    "    min_repeat_ms=min_repeat_ms,\n",
    "    enable_cpu_cache_flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tuning option\n",
    "\n",
    "We use an XGBoost algorithim for guiding the search. For a production job, you will want to set the number of trials to be larger than the value of 20 used here. For CPU we recommend 1500, for GPU 3000-4000. \n",
    "\n",
    "The `early_stopping` parameter is the minimum number of trails to run before a condition that stops the search early can be applied. \n",
    "\n",
    "The measure option indicates where trial code will be built, and where it will be run. In this case, weâ€™re using the `LocalRunner` we just created and a `LocalBuilder`. The `tuning_records` option specifies a file to write the tuning data to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_option = {\n",
    "    \"tuner\": \"xgb\",\n",
    "    \"trials\": 20,\n",
    "    \"early_stopping\": 100,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
    "    ),\n",
    "    \"tuning_records\": \"resnet-50-v2-autotuning.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute tuning\n",
    "\n",
    "`mod` and `params` are the outputs from `mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)`.\n",
    "We use `XGBTuner` as tuner to tune our mod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.autotvm.tuner import XGBTuner\n",
    "\n",
    "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
    "\n",
    "# Tune the extracted tasks sequentially.\n",
    "for i, task in enumerate(tasks):\n",
    "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "\n",
    "    # choose tuner\n",
    "    tuner = \"xgb\"\n",
    "\n",
    "    # create tuner\n",
    "    if tuner == \"xgb\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"reg\")\n",
    "    elif tuner == \"xgb_knob\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"knob\")\n",
    "    elif tuner == \"xgb_itervar\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"itervar\")\n",
    "    elif tuner == \"xgb_curve\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"reg\", feature_type=\"curve\")\n",
    "    elif tuner == \"xgb_rank\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
    "    elif tuner == \"xgb_rank_knob\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"knob\")\n",
    "    elif tuner == \"xgb_rank_itervar\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"itervar\")\n",
    "    elif tuner == \"xgb_rank_curve\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank\", feature_type=\"curve\")\n",
    "    elif tuner == \"xgb_rank_binary\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\")\n",
    "    elif tuner == \"xgb_rank_binary_knob\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"knob\")\n",
    "    elif tuner == \"xgb_rank_binary_itervar\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"itervar\")\n",
    "    elif tuner == \"xgb_rank_binary_curve\":\n",
    "        tuner_obj = XGBTuner(task, loss_type=\"rank-binary\", feature_type=\"curve\")\n",
    "    elif tuner == \"ga\":\n",
    "        tuner_obj = GATuner(task, pop_size=50)\n",
    "    elif tuner == \"random\":\n",
    "        tuner_obj = RandomTuner(task)\n",
    "    elif tuner == \"gridsearch\":\n",
    "        tuner_obj = GridSearchTuner(task)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid tuner: \" + tuner)\n",
    "\n",
    "    tuner_obj.tune(\n",
    "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
    "        early_stopping=tuning_option[\"early_stopping\"],\n",
    "        measure_option=tuning_option[\"measure_option\"],\n",
    "        callbacks=[\n",
    "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
    "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling an Optimized Model with Tuning Data\n",
    "\n",
    "`autotvm.apply_history_best(tuning_option[\"tuning_records\"])` using the result of tuning to compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
    "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
